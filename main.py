import streamlit as st
from langchain.chat_models.gigachat import GigaChat
from typing import Optional, Type
import dotenv
import os
from langchain.pydantic_v1 import BaseModel, Field
from services.retrievers_ensemble_retriever import get_ensemble_retriver
from langchain.tools import BaseTool
from langchain.agents import (
    AgentExecutor,
    create_gigachat_functions_agent,
)
from langchain.agents.gigachat_functions_agent.base import (
    format_to_gigachat_function_messages,
)
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

try:
    dotenv.load_dotenv()
except:
    pass

GIGACHAT_API_CREDENTIALS = os.environ.get("GIGACHAT_API_CREDENTIALS")

class SearchInput(BaseModel):
    question: str = Field(
        description="Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ"
    )

class SearchTool(BaseTool):
    name = "search"
    description = """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ Ğ¿Ğ¾Ğ¸ÑĞº Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¿Ğ¾ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğµ Ğ² Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… 
"""
    args_schema: Type[BaseModel] = SearchInput

    def _run(
        self,
        question: str,
        run_manager=None
    ) -> str:
        result = get_ensemble_retriver().get_relevant_documents(question)
        
        result_string = "Agent Tool RAG: ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸:\n\n"
        for index, item in enumerate(result):
            result_string += f"{index+1} \t" + item.page_content
            result_string += "\n" + item.metadata['source'] + "\n\n"
            
        return result_string

giga = GigaChat(credentials=GIGACHAT_API_CREDENTIALS,
                scope='GIGACHAT_API_CORP', 
                verify_ssl_certs=False,
                model = 'GigaChat-Pro-preview',
                profanity_check=False,
                timeout=600,
                #streaming=True
                )

tools = [SearchTool()]
agent = create_gigachat_functions_agent(giga, tools)

# AgentExecutor ÑĞ¾Ğ·Ğ´Ğ°ĞµÑ‚ ÑÑ€ĞµĞ´Ñƒ, Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ±ÑƒĞ´ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ°Ğ³ĞµĞ½Ñ‚
agent_executor = AgentExecutor(
    agent=agent, tools=tools, verbose=False, return_intermediate_steps=True
)
system = f"""Ğ¢Ñ‹ Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ¸ ÑĞ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ¿Ğ¾ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ğµ

Ğ£ Ñ‚ĞµĞ±Ñ ĞµÑÑ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸:
ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ RAG context Ğ¸Ğ· Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
"""  # noqa
chat_history = [SystemMessage(content=system)]

with st.sidebar:
    "ĞÑ‚Ğ²ĞµÑ‚Ñ‹ Ğ¾Ñ‚ Ñ‡Ğ°Ñ‚-Ğ±Ğ¾Ñ‚Ğ° Ğ½Ğ¾ÑÑÑ‚ ÑĞ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€."

    "ĞÑ‚Ğ²ĞµÑ‚Ñ‹ Ğ¾Ñ‚ Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ° Ğ½Ğµ ÑĞ²Ğ»ÑÑÑ‚ÑÑ Ğ²Ñ€Ğ°Ñ‡ĞµĞ±Ğ½Ğ¾Ğ¹ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹, Ğ»ÑƒÑ‡ÑˆĞµ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒÑÑ Ğ² Ğ¼ĞµĞ´. Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ."

st.title("ğŸ’¬ ĞœĞµĞ´ Ñ‡Ğ°Ñ‚-Ğ±Ğ¾Ñ‚")
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Ğ’Ğ°Ñ Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¼ĞµĞ´ Ñ‡Ğ°Ñ‚-Ğ±Ğ¾Ñ‚"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if question := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": question})
    st.chat_message("user").write(question)

    result = agent_executor.invoke(
        {
            "chat_history": chat_history,
            "input": question,
        }
    )
    #result = giga(st.session_state["messages"])
    msg = result["output"]
    details = result["intermediate_steps"]
    if len(details) > 0:
        tool_question, tool_answer = details[0]
        st.session_state.messages.append({"role": "assistant", "content": tool_answer})
        st.chat_message("assistant", avatar='ğŸ¤–').write(tool_answer)
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)