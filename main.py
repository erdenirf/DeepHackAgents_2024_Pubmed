import streamlit as st
from langchain.chat_models.gigachat import GigaChat
from typing import Optional, Type
from langchain.chains import RetrievalQA
import dotenv
import os
from langchain.pydantic_v1 import BaseModel, Field
from services.vectorstore_connect import qdrant_vectorstore
from langchain.tools import BaseTool
from langchain.agents import (
    AgentExecutor,
    create_gigachat_functions_agent,
)
from langchain.agents.gigachat_functions_agent.base import (
    format_to_gigachat_function_messages,
)
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

try:
    dotenv.load_dotenv()
except:
    pass

GIGACHAT_API_CREDENTIALS = os.environ.get("GIGACHAT_API_CREDENTIALS")

class SearchInput(BaseModel):
    question: str = Field(
        description="–≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"
    )

class SearchTool(BaseTool):
    name = "search"
    description = """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ –º–µ–¥–∏—Ü–∏–Ω–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö 
"""
    args_schema: Type[BaseModel] = SearchInput

    def _run(
        self,
        question: str,
        run_manager=None
    ) -> str:
        msg = f"–ò—â–µ–º –≤ –±–∞–∑–µ —Å—Ç–∞—Ç–µ–π –≤–æ–ø—Ä–æ—Å: {question} "
        st.session_state.messages.append({"role": "assistant", "content": msg})
        st.chat_message("assistant").write(msg)
        result = qdrant_vectorstore.as_retriever().get_relevant_documents(question)
        
        result_string = "–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏:\n\n"
        for index, item in enumerate(result):
            result_string += f"{index+1} \t" + item.page_content
            result_string += "\n" + item.metadata['source'] + "\n\n"
            
        st.session_state.messages.append({"role": "assistant", "content": result_string})
        st.chat_message("assistant").write(result_string)
        return result_string

giga = GigaChat(credentials=GIGACHAT_API_CREDENTIALS,
                scope='GIGACHAT_API_CORP', 
                verify_ssl_certs=False,
                model = 'GigaChat-Pro-preview',
                profanity_check=False,
                timeout=600,
                #streaming=True
                )

tools = [SearchTool()]
agent = create_gigachat_functions_agent(giga, tools)

# AgentExecutor —Å–æ–∑–¥–∞–µ—Ç —Å—Ä–µ–¥—É, –≤ –∫–æ—Ç–æ—Ä–æ–π –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∞–≥–µ–Ω—Ç
agent_executor = AgentExecutor(
    agent=agent, tools=tools, verbose=False, return_intermediate_steps=False
)
system = f"""–¢—ã –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ø–æ –º–µ–¥–∏—Ü–∏–Ω–µ

–£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
–ü–æ–ª—É—á–∏—Ç—å RAG context –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
"""  # noqa
chat_history = [SystemMessage(content=system)]

#qa = RetrievalQA.from_llm(llm=giga, retriever=qdrant_vectorstore.as_retriever())

with st.sidebar:
    "–û—Ç–≤–µ—Ç—ã –æ—Ç —á–∞—Ç-–±–æ—Ç–∞ –Ω–æ—Å—è—Ç —Å–ø—Ä–∞–≤–æ—á–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä."

    "–û—Ç–≤–µ—Ç—ã –æ—Ç –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –≤—Ä–∞—á–µ–±–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π, –ª—É—á—à–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –º–µ–¥. –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é."

st.title("üí¨ –ú–µ–¥ —á–∞—Ç-–±–æ—Ç")
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "–í–∞—Å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –º–µ–¥ —á–∞—Ç-–±–æ—Ç"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if question := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": question})
    st.chat_message("user").write(question)
    #result = qa(question)
    result = agent_executor.invoke(
        {
            "chat_history": chat_history,
            "input": question,
        }
    )
    #result = giga(st.session_state["messages"])
    msg = result["output"]
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)